{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class GNNStack(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, task='node'):\n",
    "        super(GNNStack, self).__init__()\n",
    "        self.task = task\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(self.build_conv_model(input_dim, hidden_dim))\n",
    "        self.lns = nn.ModuleList()\n",
    "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "        self.lns.append(nn.LayerNorm(hidden_dim))\n",
    "        for l in range(2):\n",
    "            self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))\n",
    "\n",
    "        # post-message-passing\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.5), \n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "        if not (self.task == 'node' or self.task == 'graph'):\n",
    "            raise RuntimeError('Unknown task.')\n",
    "\n",
    "        self.dropout = 0.5\n",
    "        self.num_layers = 3\n",
    "\n",
    "    def build_conv_model(self, input_dim, hidden_dim):\n",
    "        # refer to pytorch geometric nn module for different implementation of GNNs.\n",
    "        if self.task == 'node':\n",
    "            return pyg_nn.GCNConv(input_dim, hidden_dim)\n",
    "        else:\n",
    "            return pyg_nn.GINConv(nn.Sequential(nn.Linear(input_dim, hidden_dim),\n",
    "                                  nn.ReLU(), nn.Linear(hidden_dim, hidden_dim)))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        if data.num_node_features == 0:\n",
    "          x = torch.ones(data.num_nodes, 1)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            emb = x\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            if not i == self.num_layers - 1:\n",
    "                x = self.lns[i](x)\n",
    "\n",
    "        if self.task == 'graph':\n",
    "            x = pyg_nn.global_max_pool(x, batch)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        return emb, F.log_softmax(x, dim=1),F.softmax(x,dim=1)\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.io import read_tu_data\n",
    "import os.path as osp\n",
    "\n",
    "class GraphDataset(InMemoryDataset):\n",
    "    def __init__(self, root, name, transform=None, pre_transform=None,\n",
    "                 pre_filter=None, use_node_attr=False, use_edge_attr=False):\n",
    "        self.name = name\n",
    "        super(GraphDataset, self).__init__(root, transform, pre_transform,\n",
    "                                        pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        if self.data.x is not None and not use_node_attr:\n",
    "            num_node_attributes = self.num_node_attributes\n",
    "            self.data.x = self.data.x[:, num_node_attributes:]\n",
    "        if self.data.edge_attr is not None and not use_edge_attr:\n",
    "            num_edge_attributes = self.num_edge_attributes\n",
    "            self.data.edge_attr = self.data.edge_attr[:, num_edge_attributes:]\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        name = 'raw{}'.format('')\n",
    "        return osp.join(self.root, self.name, name)\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self):\n",
    "        name = 'processed{}'.format('')\n",
    "        return osp.join(self.root, self.name, name)\n",
    "\n",
    "    @property\n",
    "    def num_node_labels(self):\n",
    "        if self.data.x is None:\n",
    "            return 0\n",
    "        for i in range(self.data.x.size(1)):\n",
    "            x = self.data.x[:, i:]\n",
    "            if ((x == 0) | (x == 1)).all() and (x.sum(dim=1) == 1).all():\n",
    "                return self.data.x.size(1) - i\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def num_node_attributes(self):\n",
    "        if self.data.x is None:\n",
    "            return 0\n",
    "        return self.data.x.size(1) - self.num_node_labels\n",
    "\n",
    "    @property\n",
    "    def num_edge_labels(self):\n",
    "        if self.data.edge_attr is None:\n",
    "            return 0\n",
    "        for i in range(self.data.edge_attr.size(1)):\n",
    "            if self.data.edge_attr[:, i:].sum() == self.data.edge_attr.size(0):\n",
    "                return self.data.edge_attr.size(1) - i\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def num_edge_attributes(self):\n",
    "        if self.data.edge_attr is None:\n",
    "            return 0\n",
    "        return self.data.edge_attr.size(1) - self.num_edge_labels\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        names = ['A', 'graph_indicator','graph_labels','node_attributes','node_labels']\n",
    "        return ['{}_{}.txt'.format(self.name, name) for name in names]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "\n",
    "    def process(self):\n",
    "        self.data, self.slices = read_tu_data(self.raw_dir, self.name)\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [self.get(idx) for idx in range(len(self))]\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "            self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.get(idx) for idx in range(len(self))]\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "            self.data, self.slices = self.collate(data_list)\n",
    "\n",
    "        torch.save((self.data, self.slices), self.processed_paths[0])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({})'.format(self.name, len(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry no gpu found!!\n",
      "Running model on cpu\n",
      "**********\n",
      "600\n",
      "4\n",
      "16\n",
      "0.5\n",
      "3\n",
      "**********\n",
      "Running for 1 fold\n",
      "480 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\torch_geometric\\deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Train Loss: 0.1796. Train accuracy: 1.0000\n",
      "Epoch 1. Train Loss: 0.9445. Train accuracy: 0.3312\n",
      "Epoch 2. Train Loss: 1.1195. Train accuracy: 0.3229\n",
      "Epoch 3. Train Loss: 1.1127. Train accuracy: 0.3229\n",
      "Epoch 4. Train Loss: 1.1181. Train accuracy: 0.3229\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-85789f094970>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[0mcnt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[0meval_train_ratio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-85789f094970>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset, task, writer)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m     \u001b[0mcrossvalid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;31m#function for calculating acc for different train-ratio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-85789f094970>\u001b[0m in \u001b[0;36mcrossvalid\u001b[1;34m(dataset, k_fold)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                     \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m                     \u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msoft\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m                     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'node'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-d732ad1c3d30>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0memb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1167\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[1;34m\"but got {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean, pstdev\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from model import *\n",
    "#from dataloader import *\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score,roc_curve,auc,classification_report,confusion_matrix\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "#args = parser.parse_args(args=[])\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('cuda', action='store_true', default=False,\n",
    "                    help='Use CUDA for training.')\n",
    "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=200,\n",
    "                    help='Number of epochs to train.')\n",
    "parser.add_argument('--lr', type=float, default=0.01,\n",
    "                    help='Initial learning rate.')\n",
    "parser.add_argument('--weight_decay', type=float, default=5e-4,\n",
    "                    help='Weight decay for optimizer.')\n",
    "parser.add_argument('--hidden', type=int, default=16,\n",
    "                    help='Number of hidden units.')\n",
    "parser.add_argument('--dropout', type=float, default=0.5,\n",
    "                    help='Dropout rate (1 - keep probability).')\n",
    "parser.add_argument('--train_split', type=float, default=0.8,\n",
    "                    help='Ratio of train split from entire dataset.Rest goes to test set')\n",
    "parser.add_argument('--batch_size', type=int, default=16,\n",
    "                    help='batch size for loading mini batches of data')\n",
    "parser.add_argument('--dataset_name', type=str, default='Kaggle_Pretwitt',\n",
    "                    help='Dataset name')\n",
    "args = parser.parse_args(args=[])\n",
    "#args = parser.parse_args()\n",
    "if args.cuda:\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "    else:\n",
    "        print(\"Sorry no gpu found!!\")\n",
    "        device=torch.device('cpu')\n",
    "        print(\"Running model on cpu\")\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "\n",
    "#Setting seed to reproduce results\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "dataset = GraphDataset(root='brain3/Github_Pretwitt/raw/', name=args.dataset_name, use_node_attr=True)\n",
    "data_size = len(dataset)\n",
    "\n",
    "#checking some of the data attributes comment out these lines if not needed to check\n",
    "print(\"*\"*10)\n",
    "print(data_size)\n",
    "print(dataset.num_features)\n",
    "print(args.hidden)\n",
    "print(args.dropout)\n",
    "print(dataset.num_classes)\n",
    "print(\"*\"*10)\n",
    "\n",
    "n_classes=dataset.num_classes\n",
    "class_list=[]\n",
    "for i in range(0,n_classes):\n",
    "    class_list.append(i)\n",
    "    \n",
    "\n",
    "#printing confusion matrix\n",
    "def show_confusion_matrix(validations, predictions):\n",
    "    LABELS=[\"COVID\",\"NON-COVID\",\"PNEUMONIA\"]\n",
    "    matrix = confusion_matrix(validations, predictions)\n",
    "    print(matrix)\n",
    "    \n",
    "\n",
    "#applying k-fold cross validation\n",
    "def crossvalid(dataset=None,k_fold=5):\n",
    "    \n",
    "    global precision,recall,f1\n",
    "    \n",
    "    \n",
    "    total_size = len(dataset)\n",
    "    fraction = 1/k_fold\n",
    "    seg = int(total_size * fraction) \n",
    "    index=0\n",
    "    test_accs=[]\n",
    "    train_time=0\n",
    "    test_time=0\n",
    "    for i in range(k_fold):\n",
    "        if(i==k_fold-1):\n",
    "            print(\"Running for {} fold\".format(index+1))\n",
    "            index=index+1\n",
    "            trll = 0\n",
    "            trlr = i * seg\n",
    "            vall = trlr\n",
    "            valr = i * seg + seg\n",
    "            trrl = valr\n",
    "            trrr = total_size\n",
    "            \n",
    "            train_left_indices = list(range(trll,trlr))\n",
    "            train_right_indices = list(range(trrl,trrr))\n",
    "            \n",
    "            train_indices = train_left_indices + train_right_indices\n",
    "            val_indices = list(range(vall,valr))\n",
    "            \n",
    "            train_set = torch.utils.data.dataset.Subset(dataset,train_indices)\n",
    "            val_set = torch.utils.data.dataset.Subset(dataset,val_indices)\n",
    "            \n",
    "            print(len(train_set),len(val_set))\n",
    "            \n",
    "            train_loader = DataLoader(train_set, batch_size=1,\n",
    "                                              shuffle=True)\n",
    "            val_loader = DataLoader(val_set, batch_size=1,\n",
    "                                              shuffle=True)\n",
    "                                              \n",
    "            \n",
    "            model = GNNStack(max(dataset.num_node_features, 1), 32, dataset.num_classes, task=task)\n",
    "            opt = optim.Adam(model.parameters(), lr=0.009)\n",
    "            \n",
    "            loss_values=[]\n",
    "            accuracy_values=[]\n",
    "            \n",
    "            train_start=time.time()  \n",
    "            for epoch in range(10):\n",
    "                total_loss = 0\n",
    "                model.train()\n",
    "                for batch in train_loader:\n",
    "                \n",
    "                    opt.zero_grad()\n",
    "                    embedding, pred, soft= model(batch)\n",
    "                    label = batch.y\n",
    "                    if task == 'node':\n",
    "                        pred = pred[batch.train_mask]\n",
    "                        label = label[batch.train_mask]\n",
    "                    loss = model.loss(pred, label)\n",
    "                    loss.backward()\n",
    "                    opt.step()\n",
    "                    total_loss += loss.item() * batch.num_graphs\n",
    "                total_loss /= len(train_loader.dataset)\n",
    "                writer.add_scalar(\"loss\", total_loss, epoch)\n",
    "    \n",
    "                if epoch % 1 == 0:\n",
    "                    train_acc = test(train_loader, model)\n",
    "                    print(\"Epoch {}. Train Loss: {:.4f}. Train accuracy: {:.4f}\".format(\n",
    "                        epoch, total_loss, train_acc))\n",
    "                    \n",
    "                    loss_values.append(total_loss)\n",
    "                    accuracy_values.append(train_acc)\n",
    "                \n",
    "                    writer.add_scalar(\"train accuracy\", train_acc, epoch)\n",
    "            \n",
    "            train_end=time.time()\n",
    "            print(\"Time taken for training: \",train_end-train_start)\n",
    "            train_time+=(train_end-train_start)\n",
    "            \n",
    "            test_start=time.time()\n",
    "            test_acc = test(val_loader, model, True)\n",
    "            test_end=time.time()\n",
    "            print(\"Test accuracy: {:.4f}\".format(test_acc))\n",
    "            print(\"Time taken for testing: \",test_end-test_start)\n",
    "            test_time+=(test_end-test_start)\n",
    "            \n",
    "            fig = plt.figure(figsize=(8,6))\n",
    "            ax = fig.add_subplot(111)\n",
    "            ax.set_title('Training loss and accuracy',fontsize=25)\n",
    "            plt.plot(loss_values, color='red',label='Loss')\n",
    "            plt.plot(accuracy_values, color='blue',label='Accuracy')\n",
    "            plt.xticks(fontsize=20)\n",
    "            plt.yticks(fontsize=20)\n",
    "            ax.set_xlabel('Epoch',fontsize=25)\n",
    "            ax.set_ylabel('Loss and Accuracy',fontsize=25)\n",
    "            ax.legend(loc='best',fontsize=20)\n",
    "            plt.savefig(f\"{k_fold}-fold_\"+args.dataset_name+\"_\"+str(i+1)+\".svg\",format=\"svg\")\n",
    "            \n",
    "            test_accs.append(test_acc)\n",
    "                \n",
    "    precision/=k_fold\n",
    "    recall/=k_fold\n",
    "    f1/=k_fold\n",
    "    avg_test=sum(test_accs)/len(test_accs)\n",
    "    train_time/=k_fold\n",
    "    test_time/=k_fold\n",
    "    print(\"------------\")\n",
    "    print(\"{} fold test accuracy {:.4f}, precision {:.4f}, recall {:.4f}, F1-score {:.4f}\".format(k_fold,avg_test,precision,recall,f1))\n",
    "    print(\"Average training time {:.3f}, average testing time {:.3f}\".format(train_time,test_time))    \n",
    "\n",
    "\n",
    "def train(dataset, task, writer):\n",
    "    crossvalid(dataset)\n",
    "    \n",
    "#function for calculating acc for different train-ratio\n",
    "def eval_train_ratio(dataset, task, writer):\n",
    "    \n",
    "    train_ratios=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "    test_accuracies=[]\n",
    "    train_accuracies=[]\n",
    "    for tr in train_ratios:\n",
    "        if task == 'graph':\n",
    "            data_size = len(dataset)\n",
    "            train_loader = DataLoader(dataset[:int(data_size * tr)], batch_size=1, shuffle=True)\n",
    "            test_loader = DataLoader(dataset[int(data_size * tr):], batch_size=1, shuffle=True)\n",
    "        else:\n",
    "            test_loader = train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "        print(\"Train ratio: {:.1f}. No of training graphs: {}. No of testing graphs: {}\".format(tr,len(train_loader),len(test_loader)))\n",
    "        \n",
    "        model = GNNStack(max(dataset.num_node_features, 1), 32, dataset.num_classes, task=task)\n",
    "        opt = optim.Adam(model.parameters(), lr=0.009)\n",
    "\n",
    "        for epoch in range(10):\n",
    "            total_loss = 0\n",
    "            model.train()\n",
    "            for batch in train_loader:\n",
    "            \n",
    "                opt.zero_grad()\n",
    "                embedding, pred ,_= model(batch)\n",
    "                label = batch.y\n",
    "                if task == 'node':\n",
    "                    pred = pred[batch.train_mask]\n",
    "                    label = label[batch.train_mask]\n",
    "                loss = model.loss(pred, label)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                total_loss += loss.item() * batch.num_graphs\n",
    "            total_loss /= len(train_loader.dataset)\n",
    "        train_acc = test(train_loader, model)\n",
    "        test_acc = test(test_loader, model, True)\n",
    "        print(\"Test accuracy: {:.4f}\".format(test_acc))\n",
    "        test_accuracies.append(test_acc)\n",
    "        train_accuracies.append(train_acc)\n",
    "        \n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title('Training and testing accuracy',fontsize=25)\n",
    "    plt.plot(train_ratios, train_accuracies, color='red', marker= 'o',label='Train Acc')\n",
    "    plt.plot(train_ratios, test_accuracies, color='blue',marker= 'o', label='Test Acc')\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=16)\n",
    "    ax.set_xlabel('Train Ratio',fontsize=25)\n",
    "    ax.set_ylabel('Training and testing accuracy',fontsize=25)\n",
    "    ax.legend(loc='best',fontsize=20)\n",
    "    #plt.show()\n",
    "    plt.savefig(f\"iterative_training_\"+args.dataset_name+\".svg\",format=\"svg\")\n",
    "    \n",
    "def test(loader, model, is_test=False,is_validation=False):\n",
    "    global precision,recall,f1\n",
    "    global class_list,n_classes\n",
    "    global cnt\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    glabel=[]\n",
    "    glabel1=[]\n",
    "    gpred=[]\n",
    "    gscore=[]\n",
    "    for data in loader:\n",
    "        with torch.no_grad():\n",
    "            emb, pred,soft = model(data)\n",
    "            var=soft.numpy()[0]\n",
    "            pred = pred.argmax(dim=1)\n",
    "            label = data.y\n",
    "            \n",
    "            \n",
    "            if(is_test): \n",
    "                glabel.append(label.numpy()[0])\n",
    "                glabel1.append(label.numpy())   \n",
    "                gpred.append(pred.numpy()[0])\n",
    "                gscore.append(var)\n",
    "            \n",
    "\n",
    "        if model.task == 'node':\n",
    "            mask = data.val_mask if is_validation else data.test_mask\n",
    "            pred = pred[mask]\n",
    "            label = data.y[mask]\n",
    "            \n",
    "        correct += pred.eq(label).sum().item()\n",
    "    \n",
    "    if model.task == 'graph':\n",
    "        total = len(loader.dataset) \n",
    "    else:\n",
    "        total = 0\n",
    "        for data in loader.dataset:\n",
    "            total += torch.sum(data.test_mask).item()\n",
    "    \n",
    "    if(is_test):\n",
    "        glabel=np.array(glabel)\n",
    "        glabel1=np.array(glabel1)\n",
    "        gpred=np.array(gpred)\n",
    "        gscore=np.array(gscore)\n",
    "        enlabel=to_categorical(glabel1,n_classes)\n",
    "        \n",
    "        \n",
    "        \n",
    "        p=precision_score(glabel, gpred, average=\"micro\")\n",
    "        r=recall_score(glabel, gpred, average=\"micro\")\n",
    "        f=f1_score(glabel, gpred, average=\"micro\")\n",
    "        \n",
    "        print('F1: {}'.format(f))\n",
    "        print('Precision: {}'.format(p))\n",
    "        print('Recall: {}'.format(r))\n",
    "        precision+=p\n",
    "        recall+=r\n",
    "        f1+=f\n",
    "        \n",
    "        print(\"\\n...confusion matrix and classification report....\\n\")\n",
    "        show_confusion_matrix(glabel,gpred)\n",
    "        print(classification_report(glabel,gpred,digits=5))\n",
    "\n",
    "        \n",
    "        #generate roc curve\n",
    "        tpr=dict()\n",
    "        fpr=dict()\n",
    "        roc_auc=dict()\n",
    "        for i in range(n_classes):\n",
    "            fpr[i], tpr[i], _= roc_curve(enlabel[:, i], gscore[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        fig = plt.figure(figsize=(8,6))\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.set_title('ROC curve',fontsize=25)\n",
    "        colors=['red','blue','green','yellow','purple','orange']\n",
    "        for i in range(n_classes):\n",
    "            plt.plot(fpr[i], tpr[i], color=colors[i],lw=2,label='ROC curve {0} (AUC = {1:0.4f})'\n",
    "             ''.format(i, roc_auc[i]))    \n",
    "        ax.set_xlabel('False postive rate',fontsize=25)\n",
    "        ax.set_ylabel('True postive rate',fontsize=25)\n",
    "        ax.legend(loc='best',fontsize=20)\n",
    "        plt.xticks(fontsize=20)\n",
    "        plt.yticks(fontsize=20)\n",
    "        plt.savefig(f\"roc_\"+args.dataset_name+\"_\"+str(cnt)+\".svg\",format=\"svg\")\n",
    "        cnt+=1\n",
    "        \n",
    "    return correct / total\n",
    "dataset = dataset.shuffle()\n",
    "task = 'graph'\n",
    "writer = SummaryWriter(\"./log/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "#globals \n",
    "precision=0\n",
    "recall=0\n",
    "f1=0\n",
    "\n",
    "cnt=1\n",
    "\n",
    "train(dataset, task, writer)\n",
    "eval_train_ratio(dataset, task, writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
